{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6559ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# ProgettoDL_FootballSegmentation ‚Äì Sam su frame estratti\n",
    "# Notebook: inferenza Sam su frame gi√† presenti + ricomposizione video\n",
    "# VERSIONE POTENZIATA E ADATTATA PER GOOGLE COLAB\n",
    "# - Modello: ViT-Large (vit_l)\n",
    "# - Modalit√†: Segment Everything (SamAutomaticMaskGenerator)\n",
    "#\n",
    "# Pipeline: (1) Setup ‚ûî (2) Percorsi ‚ûî (3) Caricamento modello ‚ûî (4) Selezione cartella frame\n",
    "#           ‚ûî (5) Inferenza ‚ûî (6) Salvataggio frame + ricomposizione video ‚ûî (7) Report ‚ûî (8) Download\n",
    "# ================================================\n",
    "\n",
    "\n",
    "# ---------- (1) Setup e import librerie ----------\n",
    "from pathlib import Path\n",
    "import sys, re, subprocess, time, zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Installazione dipendenze se non presenti (utile per Colab)\n",
    "try:\n",
    "    import segment_anything\n",
    "except ImportError:\n",
    "    print(\"Installazione di Segment Anything...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/facebookresearch/segment-anything.git\"], check=True)\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    print(\"Installazione di tqdm...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"tqdm\"], check=True)\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Controllo e setup repository Sam\n",
    "sam_repo_path = Path(\"segment-anything\")\n",
    "!git --version\n",
    "\n",
    "if not sam_repo_path.exists():\n",
    "    print(\"üõ†Ô∏è Clonazione del repository Segment Anything...\")\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\",\n",
    "        \"https://github.com/facebookresearch/segment-anything\",\n",
    "        str(sam_repo_path)\n",
    "    ], check=True)\n",
    "else:\n",
    "    print(\"‚úÖ Repository Segment Anything gi√† presente.\")\n",
    "\n",
    "\n",
    "# Aggiunge il percorso Sam per permettere l'import\n",
    "sys.path.append(str(sam_repo_path.resolve()))\n",
    "\n",
    "# Import Sam (Meta AI)\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# Funzione ausiliaria per visualizzare le maschere (MODIFICATA per opacit√† regolabile)\n",
    "def show_anns(anns, image, alpha=0.65):\n",
    "    if len(anns) == 0:\n",
    "        return image # Restituisce l'immagine originale se non ci sono maschere\n",
    "    \n",
    "    # Crea una copia dell'immagine su cui disegnare, convertita in float per il blending\n",
    "    final_image = image.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Ordina le maschere dalla pi√π grande alla pi√π piccola per disegnarle correttamente\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        # Genera un colore casuale per la maschera\n",
    "        color_mask = np.random.random(3)\n",
    "        \n",
    "        # Applica la maschera colorata all'immagine finale usando l'alpha specificato\n",
    "        final_image[m] = final_image[m] * (1 - alpha) + color_mask * alpha\n",
    "\n",
    "    # Riconverte l'immagine in formato 8-bit per il salvataggio\n",
    "    return (final_image * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "# ---------- (2) Definizione dei percorsi ----------\n",
    "# In Colab, la directory di lavoro base √® /content/\n",
    "BASE_DIR = Path.cwd()\n",
    "# Creiamo le cartelle necessarie dentro /content/\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "DATA_OUTPUTS_DIR = BASE_DIR / \"data_outputs\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Funzioni di utilit√† (incluse direttamente per semplicit√†)\n",
    "def natural_sort(file_list):\n",
    "    \"\"\"Ordina una lista di file in modo 'naturale' (es. frame2.png prima di frame10.png).\"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text.lower()\n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split('([0-9]+)', str(key))]\n",
    "    return sorted(file_list, key=alphanum_key)\n",
    "\n",
    "def save_image(image_array, path):\n",
    "    \"\"\"Salva un'immagine da un array numpy.\"\"\"\n",
    "    # OpenCV si aspetta BGR, quindi se l'array √® RGB, lo convertiamo\n",
    "    if image_array.shape[2] == 3:\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(path, image_array)\n",
    "\n",
    "\n",
    "# ---------- (3) Caricamento modello (Versione potenziata: ViT-Large) ----------\n",
    "\n",
    "# Tipo di modello SAM (ViT-B ‚Üí ViT-L)\n",
    "sam_type = \"vit_l\"\n",
    "model_filename = \"sam_vit_l_0b3195.pth\"\n",
    "model_path = MODELS_DIR / model_filename\n",
    "\n",
    "# URL ufficiale del checkpoint ViT-L\n",
    "SAM_CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\"\n",
    "\n",
    "# Se il file .pth non esiste, scaricalo automaticamente\n",
    "if model_path.exists():\n",
    "    print(f\"‚úÖ Modello trovato: {model_path.name}\")\n",
    "else:\n",
    "    print(f\"‚¨áÔ∏è File dei pesi SAM non trovato. Download in corso (circa 1.2GB)...\")\n",
    "    try:\n",
    "        import urllib.request\n",
    "        # Mostra una barra di progresso per il download\n",
    "        with tqdm(unit='B', unit_scale=True, miniters=1, desc=model_filename) as t:\n",
    "            urllib.request.urlretrieve(SAM_CHECKPOINT_URL, model_path, reporthook=lambda b, bs, ts: t.update(b*bs - t.n))\n",
    "        print(\"‚úÖ Download completato.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore nel download dei pesi: {e}\")\n",
    "        # Rimuovi file parziale in caso di errore\n",
    "        if model_path.exists():\n",
    "            model_path.unlink()\n",
    "        raise e\n",
    "\n",
    "# Istanzia il modello SAM\n",
    "sam = sam_model_registry[sam_type](checkpoint=str(model_path))\n",
    "\n",
    "# Se disponibile CUDA, usa GPU; altrimenti CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available(), \"| Device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU usata:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Sposta il modello sul device\n",
    "sam.to(device)\n",
    "\n",
    "# Inizializza il generatore automatico di maschere\n",
    "# NOTA: Puoi personalizzare i parametri qui per migliorare la qualit√† vs velocit√†\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "\n",
    "# ---------- (4) Selezione cartella frame da analizzare (Upload via Colab) ----------\n",
    "try:\n",
    "    from google.colab import files\n",
    "    # Chiede all'utente di caricare un file ZIP contenente i frame\n",
    "    print(\"Per favore, crea un file ZIP con la cartella dei frame e selezionalo tramite il pulsante qui sotto.\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    if not uploaded:\n",
    "        raise ValueError(\"Nessun file caricato. Esecuzione interrotta.\")\n",
    "\n",
    "    # Prende il nome del primo file caricato\n",
    "    zip_name = list(uploaded.keys())[0]\n",
    "    zip_path = Path(zip_name)\n",
    "\n",
    "    # Definisce la cartella di destinazione per l'estrazione\n",
    "    extract_dir = BASE_DIR / \"extracted_frames_from_zip\"\n",
    "    if extract_dir.exists():\n",
    "        import shutil\n",
    "        shutil.rmtree(extract_dir) # Pulisce la cartella se esiste gi√†\n",
    "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(f\"Estrazione di '{zip_name}' in corso...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(\"Estrazione completata.\")\n",
    "\n",
    "    # Cerca la cartella contenente i frame all'interno della directory estratta.\n",
    "    # Spesso, lo zip contiene una cartella radice.\n",
    "    # Troviamo la prima sottocartella che contiene file .png\n",
    "    found_frames_dir = None\n",
    "    for path_object in extract_dir.rglob('*.png'):\n",
    "        found_frames_dir = path_object.parent\n",
    "        break # Trovata la prima cartella con PNG, usiamo quella\n",
    "\n",
    "    if not found_frames_dir:\n",
    "         # Se non ci sono sottocartelle, i frame potrebbero essere nella root\n",
    "        if list(extract_dir.glob('*.png')):\n",
    "            found_frames_dir = extract_dir\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Nessun file PNG trovato nel file ZIP estratto in: {extract_dir}\")\n",
    "\n",
    "    frames_dir = found_frames_dir\n",
    "    print(f\"Cartella dei frame impostata su: {frames_dir}\")\n",
    "\n",
    "    # Rimuove il file zip per pulire lo spazio\n",
    "    zip_path.unlink()\n",
    "\n",
    "except ImportError:\n",
    "    # Fallback per ambienti non-Colab\n",
    "    print(\"Ambiente non Colab rilevato. Imposta manualmente 'frames_dir'.\")\n",
    "    # Inserisci qui il percorso locale se non usi Colab\n",
    "    frames_dir = Path(\"percorso/locale/alla/tua/cartella_frames\")\n",
    "\n",
    "\n",
    "if not frames_dir.exists() or not frames_dir.is_dir():\n",
    "    raise FileNotFoundError(f\"Cartella frame non trovata o non valida: '{frames_dir}'.\")\n",
    "\n",
    "# Prende tutti i frame PNG con prefisso 'frame' e li ordina in modo naturale\n",
    "frame_paths = natural_sort(list(frames_dir.glob(\"frame*.png\")))\n",
    "\n",
    "if not frame_paths:\n",
    "    raise RuntimeError(f\"Nessun frame PNG trovato in {frames_dir}\")\n",
    "\n",
    "# Estrai automaticamente l'ID clip (xx) dal nome cartella (es. .../extracted_frames_clip01). Default '00'\n",
    "m = re.search(r\"clip(\\d+)\", frames_dir.name)\n",
    "clip_id = m.group(1) if m else \"00\"\n",
    "print(f\"Trovati {len(frame_paths)} frame per la clip ID: {clip_id}\")\n",
    "\n",
    "\n",
    "# ---------- (5) Inferenza SAM (Segment Everything) sui frame ----------\n",
    "# FPS fisso per la ricostruzione del video\n",
    "fps = 25.0\n",
    "\n",
    "# !!! NUOVA IMPOSTAZIONE: REGOLA L'OPACIT√Ä DELLA MASCHERA QUI !!!\n",
    "# 1.0 = completamente opaca (colori pieni), 0.3 = molto trasparente\n",
    "MASK_OPACITY = 0.5\n",
    "\n",
    "# Cartella per i frame segmentati in /content/data_outputs:\n",
    "# \"segmented_frames_clipxx_sam\"\n",
    "seg_frames_dir = DATA_OUTPUTS_DIR / f\"segmented_frames_clip{clip_id}_sam\"\n",
    "seg_frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "segmented_frames = []  # terr√† gli array RGB annotati, nell'ordine corretto\n",
    "processed_names = []   # lista dinamica mostrata sotto la barra\n",
    "\n",
    "# Display dinamico della lista sotto la barra (mostriamo gli ultimi 50 file)\n",
    "list_handle = display(Markdown(\"_Inizio inferenza..._\"), display_id=True)\n",
    "\n",
    "# (Aggiunta timing totale inferenza)\n",
    "start_time = time.time()  # Per misurare la durata totale dell'inferenza\n",
    "\n",
    "for i, frame_path in tqdm(list(enumerate(frame_paths, start=1)), desc=f\"Inferenza SAM 'Everything' (clip {clip_id})\", unit=\"frame\"):\n",
    "    # Carica frame e converte in RGB\n",
    "    frame_bgr = cv2.imread(str(frame_path))\n",
    "    if frame_bgr is None:\n",
    "        print(f\"Attenzione: impossibile leggere il frame {frame_path}\")\n",
    "        continue\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Genera tutte le maschere per l'immagine corrente\n",
    "    masks = mask_generator.generate(frame_rgb)\n",
    "\n",
    "    # Applica overlay delle maschere sull‚Äôimmagine usando l'opacit√† definita\n",
    "    annotated = show_anns(masks, frame_rgb, alpha=MASK_OPACITY)\n",
    "\n",
    "    # Salvataggio frame segmentato\n",
    "    seg_name = f\"frame{i:04d}_clip{clip_id}_segmented_sam.png\"\n",
    "    seg_path = seg_frames_dir / seg_name\n",
    "    save_image(annotated, str(seg_path))\n",
    "\n",
    "    # Accumula in memoria per ricostruzione video\n",
    "    segmented_frames.append(annotated)\n",
    "\n",
    "    # Aggiorna lista dinamica (ultimi 10)\n",
    "    processed_names.append(seg_name)\n",
    "    last = processed_names[-10:]\n",
    "    list_handle.update(Markdown(\n",
    "        \"**Frame analizzati (ultimi 10):** \\n\" + \"<br>\".join(last) + f\"<br><br>Totale: **{len(processed_names)}**\"\n",
    "    ))\n",
    "\n",
    "if not segmented_frames:\n",
    "    raise RuntimeError(\"Nessun frame segmentato generato.\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# ---------- (6) Ricomposizione video (barra + lista dinamica coerenti) ----------\n",
    "# Salva il video in /content/data_outputs come \"segmented_clipxx_sam.mp4\"\n",
    "out_video_path = DATA_OUTPUTS_DIR / f\"segmented_clip{clip_id}_sam.mp4\"\n",
    "\n",
    "# Inizializza VideoWriter con risoluzione del primo frame\n",
    "h, w = segmented_frames[0].shape[:2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = cv2.VideoWriter(str(out_video_path), fourcc, fps, (w, h))\n",
    "\n",
    "written_names = []  # per la lista dinamica dei frame inseriti\n",
    "recon_handle = display(Markdown(\"_Inizio ricostruzione video‚Ä¶_\"), display_id=True)\n",
    "\n",
    "for i, frame in tqdm(list(enumerate(segmented_frames, start=1)), desc=\"Ricostruzione video\", unit=\"frame\"):\n",
    "    # Scrive il frame nel video (convertendo da RGB a BGR per OpenCV)\n",
    "    writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Aggiorna lista dinamica (ultimi 10)\n",
    "    name = f\"frame{i:04d}_clip{clip_id}_segmented_sam.png\"\n",
    "    written_names.append(name)\n",
    "    last_w = written_names[-10:]\n",
    "    recon_handle.update(Markdown(\n",
    "        \"**Frame inseriti nel video (ultimi 10):** \\n\" + \"<br>\".join(last_w) + f\"<br><br>Totale: **{len(written_names)}**\"\n",
    "    ))\n",
    "\n",
    "writer.release()\n",
    "\n",
    "\n",
    "# ---------- (7) Report finale ----------\n",
    "\n",
    "fps_effettivo = len(segmented_frames) / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "print(\n",
    "    \"\\n‚úÖ Segmentazione SAM (Segment Everything) avvenuta con successo.\\n\"\n",
    "    \n",
    "    \"\\nüîπ ----------------- Caratteristiche modello / architettura utilizzata -----------------\\n\"\n",
    "    f\"- Cartella notebook eseguito: {BASE_DIR}\\n\"\n",
    "    f\"- Architettura SAM: Segment Anything\\n\"\n",
    "    f\"- Tipo architettura ViT: {sam_type.upper()}\\n\"\n",
    "    f\"- Modello SAM utilizzato: {model_path.name} (cartella: {MODELS_DIR})\\n\"\n",
    "    f\"- Tipo di prompt utilizzato: Automatic Mask Generation ('Segment Everything')\\n\"\n",
    "\n",
    "    \"\\nüîπ ----------------- Caratteristiche dell‚Äôinput dell‚Äôinferenza -----------------\\n\"\n",
    "    f\"- Segmentazione relativa a: clip{clip_id}.mp4\\n\"\n",
    "    f\"- FPS della clip{clip_id}: {fps} fps\\n\"\n",
    "    f\"- Durata della clip {clip_id}: {len(segmented_frames)/fps:.3f} secondi\\n\"\n",
    "    f\"- Cartella frames estratti da clip{clip_id}: {frames_dir}\\n\"\n",
    "    f\"- Risoluzione singoli frames: {w}x{h} pixel\\n\"\n",
    "\n",
    "    \"\\nüîπ ----------------- Caratteristiche dell‚Äôoutput dell‚Äôinferenza -----------------\\n\"\n",
    "    f\"- Cartella frames segmentati (PNG): {seg_frames_dir}\\n\"\n",
    "    f\"- Video segmentato ricostruito (MP4): {out_video_path}\\n\"\n",
    "\n",
    "    \"\\nüîπ ----------------- Analisi inferenza -----------------\\n\"\n",
    "    f\"- Numero totale di frame segmentati: {len(segmented_frames)} frames\\n\"\n",
    "    f\"- Tempo totale di inferenza: {elapsed_time:.2f} secondi\\n\"\n",
    "    f\"- FPS effettivi di inferenza: {fps_effettivo:.2f} frame/secondo\\n\"\n",
    "    f\"- Tempo di inferenza medio per ciascun frame: {1/fps_effettivo:.3f} secondi/frame\\n\"\n",
    ")\n",
    "\n",
    "# =======================================\n",
    "# Fine notebook SAM (Segment Everything)\n",
    "# =======================================\n",
    "\n",
    "\n",
    "# ---------- (8) Download dei risultati in un file ZIP ----------\n",
    "try:\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "\n",
    "    # Nome del file ZIP che conterr√† tutti gli output, includendo modello e clip ID\n",
    "    output_zip_name = f\"output_SAM_{sam_type}_clip{clip_id}.zip\"\n",
    "\n",
    "    # Cartella da comprimere (la cartella principale che contiene sia i frame sia il video)\n",
    "    folder_to_zip = DATA_OUTPUTS_DIR\n",
    "\n",
    "    print(f\"\\nCompressing '{folder_to_zip}' into '{output_zip_name}'...\")\n",
    "\n",
    "    # Crea l'archivio ZIP\n",
    "    # shutil.make_archive('nome_file_senza_estensione', 'formato', 'cartella_da_zippare')\n",
    "    shutil.make_archive(output_zip_name.replace('.zip', ''), 'zip', folder_to_zip)\n",
    "\n",
    "    print(f\"Archive created! Starting download of '{output_zip_name}'...\")\n",
    "\n",
    "    # Avvia il download del file ZIP nel tuo browser\n",
    "    files.download(output_zip_name)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nDownload non disponibile: eseguire in un ambiente Google Colab per scaricare i risultati.\")\n",
    "except NameError:\n",
    "    print(\"\\nErrore: impossibile generare il file ZIP. Assicurarsi che le celle precedenti siano state eseguite correttamente.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
